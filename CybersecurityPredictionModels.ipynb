{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b0c29ed-b941-48ed-89cd-7fb9c2663e4e",
      "metadata": {
        "id": "3b0c29ed-b941-48ed-89cd-7fb9c2663e4e"
      },
      "source": [
        "# Model Runs for Cybersecurity Incident Prediction Report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "PSTydAOOBuBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa98d2b-2fe9-4428-8ae7-5c53729628bb"
      },
      "id": "PSTydAOOBuBr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1f8b071d-4ff4-4b26-8a7e-e0dde9ddc753",
      "metadata": {
        "tags": [],
        "id": "1f8b071d-4ff4-4b26-8a7e-e0dde9ddc753"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.functions import year, month, dayofmonth, hour, minute, second, dayofweek, weekofyear, col, mean, min, max, count\n",
        "from pyspark.ml import Transformer, Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler, RobustScaler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import NaiveBayes, DecisionTreeClassifier, LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "80c71d48-6a05-437b-af32-d6c859aaa8ad",
      "metadata": {
        "id": "80c71d48-6a05-437b-af32-d6c859aaa8ad"
      },
      "outputs": [],
      "source": [
        "df_train = spark.read.csv('/content/gdrive/MyDrive/GUIDE_Train.csv', header=True, inferSchema = True)\n",
        "df_test = spark.read.csv('/content/gdrive/MyDrive/GUIDE_Test.csv', header=True, inferSchema = True)\n",
        "\n",
        "df_train = df_train.drop('MitreTechniques', 'ActionGrouped', 'ActionGranular', 'EmailClusterId', 'ThreatFamily', 'ResourceType', 'Roles', 'AntispamDirection', 'SuspicionLevel', 'LastVerdict').dropna(subset=['IncidentGrade'])\n",
        "df_test = df_test.drop('MitreTechniques', 'ActionGrouped', 'ActionGranular', 'EmailClusterId', 'ThreatFamily', 'ResourceType', 'Roles', 'AntispamDirection', 'SuspicionLevel', 'LastVerdict', 'Usage')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UiZEoF6B_42",
        "outputId": "f432701f-0549-423e-8b23-17528cabbe5b"
      },
      "id": "6UiZEoF6B_42",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+----------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+\n",
            "|           Id|OrgId|IncidentId|AlertId|          Timestamp|DetectorId|AlertTitle|         Category| IncidentGrade|EntityType|EvidenceRole|DeviceId|Sha256|IpAddress|   Url|AccountSid|AccountUpn|AccountObjectId|AccountName|DeviceName|NetworkMessageId|RegistryKey|RegistryValueName|RegistryValueData|ApplicationId|ApplicationName|OAuthApplicationId|FileName|FolderPath|ResourceIdName|OSFamily|OSVersion|CountryCode|State| City|\n",
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+----------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+\n",
            "| 180388628218|    0|       612| 123247|2024-06-04 06:05:15|         7|         6|    InitialAccess|  TruePositive|        Ip|     Related|   98799|138268|       27|160396|    441377|    673934|         425863|     453297|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|         31|    6|    3|\n",
            "| 455266534868|   88|       326| 210035|2024-06-14 03:01:25|        58|        43|     Exfiltration| FalsePositive|      User|    Impacted|   98799|138268|   360606|160396|     22406|     23032|          22795|      24887|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|\n",
            "|1056561957389|  809|     58352| 712507|2024-06-13 04:52:55|       423|       298|    InitialAccess| FalsePositive|       Url|     Related|   98799|138268|   360606| 68652|    441377|    673934|         425863|     453297|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|\n",
            "|1279900258736|   92|     32992| 774301|2024-06-10 16:39:36|         2|         2|CommandAndControl|BenignPositive|       Url|     Related|   98799|138268|   360606|    13|    441377|    673934|         425863|     453297|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|\n",
            "| 214748368522|  148|      4359| 188041|2024-06-15 01:08:07|         9|        74|        Execution|  TruePositive|      User|    Impacted|   98799|138268|   360606|160396|       449|       592|            440|        479|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|\n",
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+----------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Usyf3TrCCWF",
        "outputId": "b6c4b1b2-529c-4848-b801-0c595d366a02"
      },
      "id": "4Usyf3TrCCWF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+-----------------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+\n",
            "|           Id|OrgId|IncidentId|AlertId|          Timestamp|DetectorId|AlertTitle|         Category| IncidentGrade|       EntityType|EvidenceRole|DeviceId|Sha256|IpAddress|   Url|AccountSid|AccountUpn|AccountObjectId|AccountName|DeviceName|NetworkMessageId|RegistryKey|RegistryValueName|RegistryValueData|ApplicationId|ApplicationName|OAuthApplicationId|FileName|FolderPath|ResourceIdName|OSFamily|OSVersion|CountryCode|State| City|\n",
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+-----------------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+\n",
            "|1245540519230|  657|     11767|  87199|2024-06-04 22:56:27|       524|       563|  LateralMovement|BenignPositive|             User|    Impacted|   98799|138268|   360606|160396|      2610|      3699|         425863|        863|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|\n",
            "|1400159342154|    3|     91158| 632273|2024-06-03 12:58:26|         2|         2|CommandAndControl|BenignPositive|          Machine|    Impacted|    1239|138268|   360606|160396|    441377|    673934|         425863|     453297|      2833|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       0|        0|        242| 1445|10630|\n",
            "|1279900255923|  145|     32247| 131719|2024-06-08 03:20:49|      2932|     10807|  LateralMovement|BenignPositive|          Process|     Related|   98799|  4296|   360606|160396|    441377|    673934|         425863|     453297|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|      14|        22|          3586|       5|       66|        242| 1445|10630|\n",
            "|  60129547292|  222|     15294| 917686|2024-06-12 12:07:31|         0|         0|    InitialAccess| FalsePositive|CloudLogonSession|     Related|   98799|138268|   360606|160396|    441377|    673934|         425863|     453297|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|\n",
            "| 515396080539|  363|      7615|   5944|2024-06-06 17:42:05|        27|        18|        Discovery|BenignPositive|             User|    Impacted|   98799|138268|   360606|160396|    133549|    673934|         425863|     136104|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|\n",
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+-----------------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "82bc05d3-2082-490d-8cb6-7b487ab6d2b8",
      "metadata": {
        "id": "82bc05d3-2082-490d-8cb6-7b487ab6d2b8"
      },
      "outputs": [],
      "source": [
        "class TimestampFeatureTransformer(Transformer):\n",
        "    def __init__(self):\n",
        "        super(TimestampFeatureTransformer, self).__init__()\n",
        "\n",
        "    def _transform(self, df: DataFrame) -> DataFrame:\n",
        "        return df.withColumn(\"year\", year(df[\"Timestamp\"])) \\\n",
        "                 .withColumn(\"month\", month(df[\"Timestamp\"])) \\\n",
        "                 .withColumn(\"day\", dayofmonth(df[\"Timestamp\"])) \\\n",
        "                 .withColumn(\"hour\", hour(df[\"Timestamp\"])) \\\n",
        "                 .withColumn(\"minute\", minute(df[\"Timestamp\"])) \\\n",
        "                 .withColumn(\"second\", second(df[\"Timestamp\"])) \\\n",
        "                 .withColumn(\"day_of_week\", dayofweek(df[\"Timestamp\"])) \\\n",
        "                 .withColumn(\"week_of_year\", weekofyear(df[\"Timestamp\"]))\n",
        "\n",
        "timestamp_transformer = TimestampFeatureTransformer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "462cfcb3-d462-48e0-80ad-5d408ea9c14d",
      "metadata": {
        "id": "462cfcb3-d462-48e0-80ad-5d408ea9c14d"
      },
      "source": [
        "# Naive Bayes Pipeline and Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d683c7b8-4996-44f1-8c60-db4e90a605da",
      "metadata": {
        "id": "d683c7b8-4996-44f1-8c60-db4e90a605da"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2a74c7-dafc-411e-85af-98044f34e664",
      "metadata": {
        "id": "af2a74c7-dafc-411e-85af-98044f34e664"
      },
      "outputs": [],
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "pipe_stages.append(OneHotEncoder(inputCols=[c+'_index' for c in ['Category', 'EntityType', 'EvidenceRole']], outputCols=[c+'_ohe' for c in ['Category', 'EntityType', 'EvidenceRole']]))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_ohe', 'EntityType_ohe', 'EvidenceRole_ohe',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "pipe_stages.append(assembler)\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages)\n",
        "\n",
        "pipeline_model = pipeline.fit(df_train)\n",
        "\n",
        "df_train_transformed = pipeline_model.transform(df_train)\n",
        "df_test_transformed = pipeline_model.transform(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_transformed.select(['IncidentGrade', 'target']).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa8YTihzZ5nj",
        "outputId": "c6b11c20-69cc-479c-894c-521d27f2a915"
      },
      "id": "Aa8YTihzZ5nj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------+\n",
            "| IncidentGrade|target|\n",
            "+--------------+------+\n",
            "|  TruePositive|   1.0|\n",
            "| FalsePositive|   2.0|\n",
            "| FalsePositive|   2.0|\n",
            "|BenignPositive|   0.0|\n",
            "|  TruePositive|   1.0|\n",
            "+--------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BenignPositive   0.0\n",
        "FalsePositive    2.0\n",
        "TruePositive     1.0"
      ],
      "metadata": {
        "id": "tQJPA6qNaLks"
      },
      "id": "tQJPA6qNaLks"
    },
    {
      "cell_type": "markdown",
      "id": "0f189c83-c9a9-4295-aa5d-70d24f71fcaf",
      "metadata": {
        "id": "0f189c83-c9a9-4295-aa5d-70d24f71fcaf"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca09988-6435-47ce-9bed-98841d015f69",
      "metadata": {
        "id": "0ca09988-6435-47ce-9bed-98841d015f69"
      },
      "outputs": [],
      "source": [
        "nb = NaiveBayes(featuresCol='features', labelCol='target')\n",
        "nb_model = nb.fit(df_train_transformed)\n",
        "\n",
        "train_prediction = nb_model.transform(df_train_transformed)\n",
        "test_prediction = nb_model.transform(df_test_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7a01ecb-b8c7-4cb0-94e7-ec66fd8c6dec",
      "metadata": {
        "id": "a7a01ecb-b8c7-4cb0-94e7-ec66fd8c6dec"
      },
      "source": [
        "## Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697a974d-7aa3-4053-8a53-d6e718ae9ee3",
      "metadata": {
        "id": "697a974d-7aa3-4053-8a53-d6e718ae9ee3"
      },
      "outputs": [],
      "source": [
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Results"
      ],
      "metadata": {
        "id": "bIOMeTnph_y5"
      },
      "id": "bIOMeTnph_y5"
    },
    {
      "cell_type": "code",
      "source": [
        "macrof1_class_0 = evaluator_macrof1.evaluate(train_prediction, {evaluator_macrof1.metricLabel: 0})\n",
        "print(f\"Macro F1 for class 0: {macrof1_class_0:.4f}\")\n",
        "\n",
        "macrof1_class_1 = evaluator_macrof1.evaluate(train_prediction, {evaluator_macrof1.metricLabel: 1})\n",
        "print(f\"Macro F1 for class 1: {macrof1_class_1:.4f}\")\n",
        "\n",
        "macrof1_class_2 = evaluator_macrof1.evaluate(train_prediction, {evaluator_macrof1.metricLabel: 2})\n",
        "print(f\"Macro F1 for class 2: {macrof1_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl7BX9yIh-bM",
        "outputId": "bb6c754f-b200-48b7-e651-049af1b9c178"
      },
      "id": "Bl7BX9yIh-bM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro F1 for class 0: 0.4651\n",
            "Macro F1 for class 1: 0.4651\n",
            "Macro F1 for class 2: 0.4651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEQXpkoWiHPb",
        "outputId": "b83da8ae-d592-47bc-a530-0f865780f61d"
      },
      "id": "yEQXpkoWiHPb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 for class 0: 0.5110\n",
            "F1 for class 1: 0.4992\n",
            "F1 for class 2: 0.3166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svYOuKVXiHKW",
        "outputId": "2302d808-9676-4eaa-d8e4-955edee38b05"
      },
      "id": "svYOuKVXiHKW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for class 0: 0.5077\n",
            "Precision for class 1: 0.5815\n",
            "Precision for class 2: 0.2731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r91DH6P3iHE6",
        "outputId": "64acfd89-3f31-4a38-d924-da7ce989e40b"
      },
      "id": "r91DH6P3iHE6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall for class 0: 0.5144\n",
            "Recall for class 1: 0.4373\n",
            "Recall for class 2: 0.3765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the individual values for each class I will be doing this manually.\n",
        "Note the mapping:\n",
        "- BenignPositive   0.0\n",
        "- TruePositive     1.0\n",
        "- FalsePositive    2.0\n",
        "\n",
        "I've reworked the index to go in the order of 0, 1 and 2 as normal."
      ],
      "metadata": {
        "id": "VfsukybYZh4r"
      },
      "id": "VfsukybYZh4r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7f54328-f588-4641-b229-bbcabcb66a2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7f54328-f588-4641-b229-bbcabcb66a2f",
        "outputId": "1f4fb45d-c933-48d9-dadc-726195b6daf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------+-------+-------+\n",
            "|target_prediction|    0.0|    1.0|    2.0|\n",
            "+-----------------+-------+-------+-------+\n",
            "|              1.0|1175786|1453164| 693763|\n",
            "|              0.0|2114411| 653933|1342473|\n",
            "|              2.0| 874822| 392030| 765115|\n",
            "+-----------------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Confusion Matrix for Train Set\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = [[2114411, 653933, 1342473], [1175786, 1453164, 693763], [874822, 392030, 765115]]\n",
        "\n",
        "for i in range(3):\n",
        "    tp = conf_mat[i][i]\n",
        "    fp = sum(conf_mat[j][i] for j in range(3) if j != i)\n",
        "    fn = sum(conf_mat[i][j] for j in range(3) if j != i)\n",
        "    tn = sum(conf_mat[j][k] for j in range(3) for k in range(3) if j != i and k != i)\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    print(f\"Class {i}:\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1_score}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDW0PtoiZVRX",
        "outputId": "3ab9c32f-e355-40df-cbb9-54f4a0864b3f"
      },
      "id": "RDW0PtoiZVRX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0:\n",
            "Precision: 0.5076593888287184\n",
            "Recall: 0.5143529862798563\n",
            "F1 Score: 0.5109842679337774\n",
            "\n",
            "Class 1:\n",
            "Precision: 0.5814686488521792\n",
            "Recall: 0.43734261731302104\n",
            "F1 Score: 0.4992112459291221\n",
            "\n",
            "Class 2:\n",
            "Precision: 0.273123575017911\n",
            "Recall: 0.3765390874950233\n",
            "F1 Score: 0.316600314732033\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Results"
      ],
      "metadata": {
        "id": "n1HqOlOwiAMj"
      },
      "id": "n1HqOlOwiAMj"
    },
    {
      "cell_type": "code",
      "source": [
        "macrof1_class_0 = evaluator_macrof1.evaluate(test_prediction, {evaluator_macrof1.metricLabel: 0})\n",
        "print(f\"Macro F1 for class 0: {macrof1_class_0:.4f}\")\n",
        "\n",
        "macrof1_class_1 = evaluator_macrof1.evaluate(test_prediction, {evaluator_macrof1.metricLabel: 1})\n",
        "print(f\"Macro F1 for class 1: {macrof1_class_1:.4f}\")\n",
        "\n",
        "macrof1_class_2 = evaluator_macrof1.evaluate(test_prediction, {evaluator_macrof1.metricLabel: 2})\n",
        "print(f\"Macro F1 for class 2: {macrof1_class_2:.4f}\")\n",
        "\n",
        "# verify results: while they are the same this may be a weighted average"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4X3ox3UgQFv",
        "outputId": "6b44a5e9-29d3-47a5-ebce-b14760b47c63"
      },
      "id": "U4X3ox3UgQFv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro F1 for class 0: 0.4697\n",
            "Macro F1 for class 1: 0.4697\n",
            "Macro F1 for class 2: 0.4697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSuODyeSgQLk",
        "outputId": "d446efae-9de9-4ead-b046-18e154f64b6a"
      },
      "id": "ZSuODyeSgQLk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 for class 0: 0.4978\n",
            "F1 for class 1: 0.5244\n",
            "F1 for class 2: 0.3246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV5BCe8GgR9y",
        "outputId": "7ce94d96-438a-4162-add0-924e103a12f8"
      },
      "id": "gV5BCe8GgR9y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for class 0: 0.4898\n",
            "Precision for class 1: 0.6103\n",
            "Precision for class 2: 0.2831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVTxv_d1fZEj",
        "outputId": "0a129fc0-ba11-43e0-9164-f5d1b76c9c9d"
      },
      "id": "AVTxv_d1fZEj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall for class 0: 0.5061\n",
            "Recall for class 1: 0.4597\n",
            "Recall for class 2: 0.3803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd3534b0-68aa-491a-bfa4-bd4f156130ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd3534b0-68aa-491a-bfa4-bd4f156130ad",
        "outputId": "2019eeab-c73e-456b-d396-38e1e90eed45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------+------+------+\n",
            "|target_prediction|   0.0|   1.0|   2.0|\n",
            "+-----------------+------+------+------+\n",
            "|              1.0|527797|686085|278472|\n",
            "|              0.0|887183|275040|590717|\n",
            "|              2.0|396358|163056|343284|\n",
            "+-----------------+------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Confusion Matrix for Test Set\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = [[887183, 275040, 590717], [527797, 686085, 278472], [396358, 163056, 343284]]\n",
        "\n",
        "for i in range(3):\n",
        "    tp = conf_mat[i][i]\n",
        "    fp = sum(conf_mat[j][i] for j in range(3) if j != i)\n",
        "    fn = sum(conf_mat[i][j] for j in range(3) if j != i)\n",
        "    tn = sum(conf_mat[j][k] for j in range(3) for k in range(3) if j != i and k != i)\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    print(f\"Class {i}:\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1_score}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAT7qWmqdmJm",
        "outputId": "e8db8520-cca6-4de5-904e-e012ac801220"
      },
      "id": "VAT7qWmqdmJm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0:\n",
            "Precision: 0.4897942846669147\n",
            "Recall: 0.5061114470546625\n",
            "F1 Score: 0.49781919367681204\n",
            "\n",
            "Class 1:\n",
            "Precision: 0.6102976300079791\n",
            "Recall: 0.45973341445796373\n",
            "F1 Score: 0.5244225664858295\n",
            "\n",
            "Class 2:\n",
            "Precision: 0.28312712942886153\n",
            "Recall: 0.3802866517927369\n",
            "F1 Score: 0.32459219609194717\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7dcc5e-264e-4acc-823c-0c9de7306a1f",
      "metadata": {
        "id": "ad7dcc5e-264e-4acc-823c-0c9de7306a1f"
      },
      "source": [
        "# Decision Tree Classifier Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b2034c1-b0c8-4661-a096-782d719b1600",
      "metadata": {
        "id": "0b2034c1-b0c8-4661-a096-782d719b1600"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891148d9-50e6-4303-be24-c9804888b009",
      "metadata": {
        "id": "891148d9-50e6-4303-be24-c9804888b009"
      },
      "outputs": [],
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_index', 'EntityType_index', 'EvidenceRole_index',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "pipe_stages.append(assembler)\n",
        "\n",
        "dt = DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\", maxBins=33)\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [dt])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKMkiwCZGirp"
      },
      "id": "QKMkiwCZGirp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f8680881-9eb1-4c54-91a8-e1c702ab981d",
      "metadata": {
        "id": "f8680881-9eb1-4c54-91a8-e1c702ab981d"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With Grid Search Cross Validation"
      ],
      "metadata": {
        "id": "T3jjpIxQ59kf"
      },
      "id": "T3jjpIxQ59kf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "854d537e-2b96-4990-8d3e-1aeff446e1ba",
      "metadata": {
        "id": "854d537e-2b96-4990-8d3e-1aeff446e1ba"
      },
      "outputs": [],
      "source": [
        "param_grid = (ParamGridBuilder()\n",
        "              .addGrid(dt.maxDepth, [5, 10])\n",
        "              # .addGrid(dt.maxBins, [33, 64]) # 33 because min maxBin must be largest categorical\n",
        "              .addGrid(dt.minInstancesPerNode, [1, 5])\n",
        "              .build())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efa30ded-4cae-4808-8b0d-ba1101477ef8",
      "metadata": {
        "id": "efa30ded-4cae-4808-8b0d-ba1101477ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "b3a4f9b6-9b9b-43d0-fa95-9e05a5ffa280"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b7ba1bccdd3d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcv_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             )\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mmetrics_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", metricName=\"f1\")\n",
        "\n",
        "cross_validator = CrossValidator(\n",
        "    estimator=pipeline,\n",
        "    estimatorParamMaps=param_grid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=3\n",
        ")\n",
        "\n",
        "cv_model = cross_validator.fit(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3eefaf6-80bc-4dd5-8d54-67109e50dc69",
      "metadata": {
        "id": "c3eefaf6-80bc-4dd5-8d54-67109e50dc69"
      },
      "outputs": [],
      "source": [
        "best_dt = cv_model.bestModel.stages[-1]\n",
        "\n",
        "print(\"Best maxDepth:\", best_dt.getMaxDepth())\n",
        "print(\"Best maxBins:\", best_dt.getMaxBins())\n",
        "print(\"Best minInstancesPerNode:\", best_dt.getMinInstancesPerNode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4b39db5-cb92-4b9a-b874-d52f7475e19d",
      "metadata": {
        "id": "c4b39db5-cb92-4b9a-b874-d52f7475e19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "18b63d3f-a0ec-4aea-b016-04a74a7d3628"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cv_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c3d2fcba350b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv_model' is not defined"
          ]
        }
      ],
      "source": [
        "train_prediction = cv_model.bestModel.transform(df_train)\n",
        "test_prediction = cv_model.bestModel.transform(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to Google Colab limits this is constantly crashing the notebook. I elect to conduct manual tuning instead"
      ],
      "metadata": {
        "id": "ot2NPuohJ_fy"
      },
      "id": "ot2NPuohJ_fy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without Grid Search CV"
      ],
      "metadata": {
        "id": "t76kbLAE56Vj"
      },
      "id": "t76kbLAE56Vj"
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(df_train)"
      ],
      "metadata": {
        "id": "-HZvoZ4G55rt"
      },
      "id": "-HZvoZ4G55rt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)"
      ],
      "metadata": {
        "id": "kPOIhi8A_AbN"
      },
      "id": "kPOIhi8A_AbN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "74f8ccea-d5d6-4c7f-8738-4d5e968999bf",
      "metadata": {
        "id": "74f8ccea-d5d6-4c7f-8738-4d5e968999bf"
      },
      "source": [
        "## Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "9KDJy2DUjxbA"
      },
      "id": "9KDJy2DUjxbA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0444fb6-7096-41d6-a125-030951a6159d",
      "metadata": {
        "id": "a0444fb6-7096-41d6-a125-030951a6159d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8839d8a-73e1-4e2f-caaa-17dc6598e870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.6510\n",
            "F1 for class 0: 0.7304\n",
            "F1 for class 1: 0.6796\n",
            "F1 for class 2: 0.4434\n",
            "Precision for class 0: 0.5894\n",
            "Precision for class 1: 0.9440\n",
            "Precision for class 2: 0.7224\n",
            "Recall for class 0: 0.9602\n",
            "Recall for class 1: 0.5309\n",
            "Recall for class 2: 0.3199\n",
            "\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0|1436016|1764142|122555|\n",
            "|              0.0|3947087|  36551|127179|\n",
            "|              2.0|1313769|  68190|650008|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "id": "Yu8f5xi7lvTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7acee3fd-2e36-4773-9661-a06cb5218211"
      },
      "id": "Yu8f5xi7lvTq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.6663\n",
            "F1 for class 0: 0.7264\n",
            "F1 for class 1: 0.7094\n",
            "F1 for class 2: 0.4782\n",
            "Precision for class 0: 0.5874\n",
            "Precision for class 1: 0.9573\n",
            "Precision for class 2: 0.7422\n",
            "Recall for class 0: 0.9518\n",
            "Recall for class 1: 0.5635\n",
            "Recall for class 2: 0.3527\n",
            "\n",
            "+-----------------+-------+------+------+\n",
            "|target_prediction|    0.0|   1.0|   2.0|\n",
            "+-----------------+-------+------+------+\n",
            "|              1.0| 605489|840936| 45929|\n",
            "|              0.0|1668452| 19838| 64650|\n",
            "|              2.0| 566583| 17700|318415|\n",
            "+-----------------+-------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deeper DT2\n",
        "\n",
        "Trying a deeper Decision Tree since the last was so successful."
      ],
      "metadata": {
        "id": "4dLFwm8lGD5y"
      },
      "id": "4dLFwm8lGD5y"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_index', 'EntityType_index', 'EvidenceRole_index',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "pipe_stages.append(assembler)\n",
        "\n",
        "dt = DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\", maxDepth=10, maxBins=33)\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [dt])\n",
        "\n",
        "model = pipeline.fit(df_train)\n",
        "\n",
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)\n",
        "\n",
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "r-APJKJaGCh6"
      },
      "id": "r-APJKJaGCh6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRAFruX9GSUa",
        "outputId": "e1a552ec-41a3-46cc-f6a3-e3ffa0dafdc9"
      },
      "id": "LRAFruX9GSUa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.7790\n",
            "F1 for class 0: 0.8085\n",
            "F1 for class 1: 0.8099\n",
            "F1 for class 2: 0.6687\n",
            "Precision for class 0: 0.7088\n",
            "Precision for class 1: 0.8861\n",
            "Precision for class 2: 0.8945\n",
            "Recall for class 0: 0.9408\n",
            "Recall for class 1: 0.7458\n",
            "Recall for class 2: 0.5339\n",
            "\n",
            "+-----------------+-------+-------+-------+\n",
            "|target_prediction|    0.0|    1.0|    2.0|\n",
            "+-----------------+-------+-------+-------+\n",
            "|              1.0| 798139|2478045|  46529|\n",
            "|              0.0|3867348| 162010|  81459|\n",
            "|              2.0| 790728| 156433|1084806|\n",
            "+-----------------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnMhJiwuGSOh",
        "outputId": "79fc84ef-7603-4f0c-ed9b-d8c17625c74a"
      },
      "id": "YnMhJiwuGSOh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.7677\n",
            "F1 for class 0: 0.7936\n",
            "F1 for class 1: 0.8088\n",
            "F1 for class 2: 0.6495\n",
            "Precision for class 0: 0.7014\n",
            "Precision for class 1: 0.8726\n",
            "Precision for class 2: 0.8340\n",
            "Recall for class 0: 0.9137\n",
            "Recall for class 1: 0.7536\n",
            "Recall for class 2: 0.5318\n",
            "\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0| 344283|1124694| 23377|\n",
            "|              0.0|1601582|  79153| 72205|\n",
            "|              2.0| 337526|  85095|480077|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DT3\n"
      ],
      "metadata": {
        "id": "MRPhpZr-PPyd"
      },
      "id": "MRPhpZr-PPyd"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_index', 'EntityType_index', 'EvidenceRole_index',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "pipe_stages.append(assembler)\n",
        "\n",
        "dt = DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\", maxDepth=15, maxBins=33)\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [dt])\n",
        "\n",
        "model = pipeline.fit(df_train)\n",
        "\n",
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)\n",
        "\n",
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "30QGmd19PV9A"
      },
      "id": "30QGmd19PV9A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-f-2i_9PV4t",
        "outputId": "d4af7e5f-699f-443b-8725-77b31ecac865"
      },
      "id": "C-f-2i_9PV4t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.8661\n",
            "F1 for class 0: 0.8760\n",
            "F1 for class 1: 0.8827\n",
            "F1 for class 2: 0.8191\n",
            "Precision for class 0: 0.8200\n",
            "Precision for class 1: 0.9313\n",
            "Precision for class 2: 0.8827\n",
            "Recall for class 0: 0.9402\n",
            "Recall for class 1: 0.8389\n",
            "Recall for class 2: 0.7641\n",
            "\n",
            "+-----------------+-------+-------+-------+\n",
            "|target_prediction|    0.0|    1.0|    2.0|\n",
            "+-----------------+-------+-------+-------+\n",
            "|              1.0| 444004|2787281|  91428|\n",
            "|              0.0|3864842| 130981| 114994|\n",
            "|              2.0| 404631|  74663|1552673|\n",
            "+-----------------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjL2fuFZPVxg",
        "outputId": "b755821b-3900-4160-de28-632ea1590622"
      },
      "id": "DjL2fuFZPVxg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.8302\n",
            "F1 for class 0: 0.8430\n",
            "F1 for class 1: 0.8562\n",
            "F1 for class 2: 0.7625\n",
            "Precision for class 0: 0.7949\n",
            "Precision for class 1: 0.8990\n",
            "Precision for class 2: 0.8046\n",
            "Recall for class 0: 0.8972\n",
            "Recall for class 1: 0.8173\n",
            "Recall for class 2: 0.7245\n",
            "\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0| 212508|1219723| 60123|\n",
            "|              0.0|1572668|  81514| 98758|\n",
            "|              2.0| 193169|  55487|654042|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DT4\n",
        "\n",
        "Going to depth 30 since its worked so well. 30 is the maximum allowed depth in PySpark"
      ],
      "metadata": {
        "id": "YUunmaPwZjAJ"
      },
      "id": "YUunmaPwZjAJ"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_index', 'EntityType_index', 'EvidenceRole_index',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "pipe_stages.append(assembler)\n",
        "\n",
        "dt = DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\", maxDepth=30, maxBins=33)\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [dt])\n",
        "\n",
        "model = pipeline.fit(df_train)\n",
        "\n",
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)\n",
        "\n",
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "pBcaxZm1Zhh1"
      },
      "id": "pBcaxZm1Zhh1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBScrmg2ZtR9",
        "outputId": "641dd183-0175-4bba-e523-8d995a9ff024"
      },
      "id": "pBScrmg2ZtR9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.9731\n",
            "F1 for class 0: 0.9743\n",
            "F1 for class 1: 0.9760\n",
            "F1 for class 2: 0.9660\n",
            "Precision for class 0: 0.9663\n",
            "Precision for class 1: 0.9812\n",
            "Precision for class 2: 0.9742\n",
            "Recall for class 0: 0.9825\n",
            "Recall for class 1: 0.9709\n",
            "Recall for class 2: 0.9579\n",
            "\n",
            "+-----------------+-------+-------+-------+\n",
            "|target_prediction|    0.0|    1.0|    2.0|\n",
            "+-----------------+-------+-------+-------+\n",
            "|              1.0|  75412|3225929|  21372|\n",
            "|              0.0|4039037|  41647|  30133|\n",
            "|              2.0|  65466|  20076|1946425|\n",
            "+-----------------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hguujtvQZtIX",
        "outputId": "43c55304-71e0-444c-a5df-6ed40dbbc898"
      },
      "id": "hguujtvQZtIX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.8572\n",
            "F1 for class 0: 0.8671\n",
            "F1 for class 1: 0.8758\n",
            "F1 for class 2: 0.8075\n",
            "Precision for class 0: 0.8587\n",
            "Precision for class 1: 0.8818\n",
            "Precision for class 2: 0.8140\n",
            "Recall for class 0: 0.8756\n",
            "Recall for class 1: 0.8699\n",
            "Recall for class 2: 0.8010\n",
            "\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0| 140694|1298177| 53483|\n",
            "|              0.0|1534955| 106241|111744|\n",
            "|              2.0| 111873|  67754|723071|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DT5\n",
        "\n",
        "I will try to change min instances now. Going extreme first with 500."
      ],
      "metadata": {
        "id": "laa1HK39gtPZ"
      },
      "id": "laa1HK39gtPZ"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_index', 'EntityType_index', 'EvidenceRole_index',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "pipe_stages.append(assembler)\n",
        "\n",
        "dt = DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\", maxDepth=30, minInstancesPerNode=500, maxBins=33)\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [dt])\n",
        "\n",
        "model = pipeline.fit(df_train)\n",
        "\n",
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)\n",
        "\n",
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "M6rr3uU2gvC2"
      },
      "id": "M6rr3uU2gvC2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X5eRNKQhH_s",
        "outputId": "dc8285fd-f3b8-453d-eb68-f8db3d2465d4"
      },
      "id": "-X5eRNKQhH_s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.9106\n",
            "F1 for class 0: 0.9187\n",
            "F1 for class 1: 0.9194\n",
            "F1 for class 2: 0.8797\n",
            "Precision for class 0: 0.9026\n",
            "Precision for class 1: 0.9297\n",
            "Precision for class 2: 0.8969\n",
            "Recall for class 0: 0.9353\n",
            "Recall for class 1: 0.9094\n",
            "Recall for class 2: 0.8631\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdOvC1-xhH3_",
        "outputId": "35484e33-1253-49cd-c76a-966907875457"
      },
      "id": "rdOvC1-xhH3_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.8592\n",
            "F1 for class 0: 0.8690\n",
            "F1 for class 1: 0.8813\n",
            "F1 for class 2: 0.8038\n",
            "Precision for class 0: 0.8589\n",
            "Precision for class 1: 0.8878\n",
            "Precision for class 2: 0.8128\n",
            "Recall for class 0: 0.8792\n",
            "Recall for class 1: 0.8748\n",
            "Recall for class 2: 0.7951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train')\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()\n",
        "\n",
        "print('Test')\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oJCzKhKltYX",
        "outputId": "bb530cfa-214c-45c6-f3f2-7efd8a6262e2"
      },
      "id": "1oJCzKhKltYX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "+-----------------+-------+-------+-------+\n",
            "|target_prediction|    0.0|    1.0|    2.0|\n",
            "+-----------------+-------+-------+-------+\n",
            "|              1.0| 220497|3021774|  80442|\n",
            "|              0.0|3844862| 144712| 121243|\n",
            "|              2.0| 194295|  83871|1753801|\n",
            "+-----------------+-------+-------+-------+\n",
            "\n",
            "Test\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0| 135348|1305558| 51448|\n",
            "|              0.0|1541268|  97843|113829|\n",
            "|              2.0| 117836|  67163|717699|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DT6\n",
        "\n",
        "Going even heavier into minInstancesPerNode"
      ],
      "metadata": {
        "id": "pr5_YPd1vxu3"
      },
      "id": "pr5_YPd1vxu3"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_index', 'EntityType_index', 'EvidenceRole_index',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "pipe_stages.append(assembler)\n",
        "\n",
        "dt = DecisionTreeClassifier(labelCol=\"target\", featuresCol=\"features\", maxDepth=30, minInstancesPerNode=1000, maxBins=33)\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [dt])\n",
        "\n",
        "model = pipeline.fit(df_train)\n",
        "\n",
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)\n",
        "\n",
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "pv5Gr5Q-vv8D"
      },
      "id": "pv5Gr5Q-vv8D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkLk8bcGw6fD",
        "outputId": "278dd08e-96cc-4ef8-bd79-114d0527389f"
      },
      "id": "ZkLk8bcGw6fD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.8963\n",
            "F1 for class 0: 0.9062\n",
            "F1 for class 1: 0.9069\n",
            "F1 for class 2: 0.8588\n",
            "Precision for class 0: 0.8865\n",
            "Precision for class 1: 0.9191\n",
            "Precision for class 2: 0.8811\n",
            "Recall for class 0: 0.9268\n",
            "Recall for class 1: 0.8951\n",
            "Recall for class 2: 0.8376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhOc7KvMw6ZB",
        "outputId": "93264fe4-9aee-4acc-ebd9-155fa8833845"
      },
      "id": "NhOc7KvMw6ZB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.8539\n",
            "F1 for class 0: 0.8614\n",
            "F1 for class 1: 0.8760\n",
            "F1 for class 2: 0.8028\n",
            "Precision for class 0: 0.8514\n",
            "Precision for class 1: 0.8803\n",
            "Precision for class 2: 0.8152\n",
            "Recall for class 0: 0.8716\n",
            "Recall for class 1: 0.8717\n",
            "Recall for class 2: 0.7907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train')\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()\n",
        "\n",
        "print('Test')\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIMptvY2w6RV",
        "outputId": "b4d6caa0-7696-4a59-93ed-2a2514861f14"
      },
      "id": "WIMptvY2w6RV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "+-----------------+-------+-------+-------+\n",
            "|target_prediction|    0.0|    1.0|    2.0|\n",
            "+-----------------+-------+-------+-------+\n",
            "|              1.0| 251545|2974138|  97030|\n",
            "|              0.0|3810073| 168041| 132703|\n",
            "|              2.0| 236247|  93709|1702011|\n",
            "+-----------------+-------+-------+-------+\n",
            "\n",
            "Test\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0| 142755|1300870| 48729|\n",
            "|              0.0|1527881| 111988|113071|\n",
            "|              2.0| 123989|  64963|713746|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "Trying fewer trees to avoid crashing. Starting with 5 and using best DT results"
      ],
      "metadata": {
        "id": "ZOFOsehmKqsX"
      },
      "id": "ZOFOsehmKqsX"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_index', 'EntityType_index', 'EvidenceRole_index',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "pipe_stages.append(assembler)\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"target\", featuresCol=\"features\", numTrees=5, maxDepth=30, minInstancesPerNode=500, maxBins=33)\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [rf])\n",
        "\n",
        "model = pipeline.fit(df_train)\n",
        "\n",
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)\n",
        "\n",
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "-RjZYdfiKoAB"
      },
      "id": "-RjZYdfiKoAB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()"
      ],
      "metadata": {
        "id": "Igbqt-c3K-g8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100b6d10-a64c-47ac-8a90-3b4366646cee"
      },
      "id": "Igbqt-c3K-g8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.8723\n",
            "F1 for class 0: 0.8800\n",
            "F1 for class 1: 0.8885\n",
            "F1 for class 2: 0.8300\n",
            "Precision for class 0: 0.8161\n",
            "Precision for class 1: 0.9393\n",
            "Precision for class 2: 0.9185\n",
            "Recall for class 0: 0.9547\n",
            "Recall for class 1: 0.8429\n",
            "Recall for class 2: 0.7571\n",
            "\n",
            "+-----------------+-------+-------+-------+\n",
            "|target_prediction|    0.0|    1.0|    2.0|\n",
            "+-----------------+-------+-------+-------+\n",
            "|              1.0| 467680|2800562|  54471|\n",
            "|              0.0|3924795| 103981|  82041|\n",
            "|              2.0| 416672|  76846|1538449|\n",
            "+-----------------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "id": "pENIzGXwK-VF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c3a8c9-6544-4556-9990-c41a83b1f1f8"
      },
      "id": "pENIzGXwK-VF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.8389\n",
            "F1 for class 0: 0.8463\n",
            "F1 for class 1: 0.8693\n",
            "F1 for class 2: 0.7741\n",
            "Precision for class 0: 0.7859\n",
            "Precision for class 1: 0.9182\n",
            "Precision for class 2: 0.8459\n",
            "Recall for class 0: 0.9168\n",
            "Recall for class 1: 0.8254\n",
            "Recall for class 2: 0.7135\n",
            "\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0| 226172|1231826| 34356|\n",
            "|              0.0|1607143|  62860| 82937|\n",
            "|              2.0| 211694|  46908|644096|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "PN1VarHgrKSy"
      },
      "id": "PN1VarHgrKSy"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "pipe_stages.append(OneHotEncoder(inputCols=[c+'_index' for c in ['Category', 'EntityType', 'EvidenceRole']], outputCols=[c+'_ohe' for c in ['Category', 'EntityType', 'EvidenceRole']]))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_ohe', 'EntityType_ohe', 'EvidenceRole_ohe',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features_raw')\n",
        "\n",
        "scaler = MinMaxScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
        "\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='target')\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [assembler, scaler, lr])\n",
        "\n",
        "model = pipeline.fit(df_train)"
      ],
      "metadata": {
        "id": "qxEOe_7Lb_n9"
      },
      "id": "qxEOe_7Lb_n9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)"
      ],
      "metadata": {
        "id": "9N9zKGP9ui8s"
      },
      "id": "9N9zKGP9ui8s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "XoWqMbV9uq4G"
      },
      "id": "XoWqMbV9uq4G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()"
      ],
      "metadata": {
        "id": "rXAyCdc1uuQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e099413-ce98-4a48-85bf-0b0148aafa79"
      },
      "id": "rXAyCdc1uuQR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.6114\n",
            "F1 for class 0: 0.7038\n",
            "F1 for class 1: 0.6705\n",
            "F1 for class 2: 0.3278\n",
            "Precision for class 0: 0.6038\n",
            "Precision for class 1: 0.7070\n",
            "Precision for class 2: 0.6219\n",
            "Recall for class 0: 0.8434\n",
            "Recall for class 1: 0.6376\n",
            "Recall for class 2: 0.2225\n",
            "\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0|1095921|2118666|108126|\n",
            "|              0.0|3466871| 477215|166731|\n",
            "|              2.0|1178822| 401008|452137|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "id": "ZbIrzUi1uw5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18764e4-dd12-4537-8bc1-aab22aeea5ad"
      },
      "id": "ZbIrzUi1uw5M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.6276\n",
            "F1 for class 0: 0.7032\n",
            "F1 for class 1: 0.6964\n",
            "F1 for class 2: 0.3670\n",
            "Precision for class 0: 0.6051\n",
            "Precision for class 1: 0.7306\n",
            "Precision for class 2: 0.6469\n",
            "Recall for class 0: 0.8393\n",
            "Recall for class 1: 0.6654\n",
            "Recall for class 2: 0.2562\n",
            "\n",
            "+-----------------+-------+------+------+\n",
            "|target_prediction|    0.0|   1.0|   2.0|\n",
            "+-----------------+-------+------+------+\n",
            "|              1.0| 452870|992938| 46546|\n",
            "|              0.0|1471230|202010| 79700|\n",
            "|              2.0| 507275|164176|231247|\n",
            "+-----------------+-------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction.show(5)"
      ],
      "metadata": {
        "id": "v1z7MPhDwZHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8eb8f1-a7e8-4319-bfed-5044374803cd"
      },
      "id": "v1z7MPhDwZHz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+-----------------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+----+-----+---+----+------+------+-----------+------------+--------------+----------------+------------------+------+---------------+---------------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|           Id|OrgId|IncidentId|AlertId|          Timestamp|DetectorId|AlertTitle|         Category| IncidentGrade|       EntityType|EvidenceRole|DeviceId|Sha256|IpAddress|   Url|AccountSid|AccountUpn|AccountObjectId|AccountName|DeviceName|NetworkMessageId|RegistryKey|RegistryValueName|RegistryValueData|ApplicationId|ApplicationName|OAuthApplicationId|FileName|FolderPath|ResourceIdName|OSFamily|OSVersion|CountryCode|State| City|year|month|day|hour|minute|second|day_of_week|week_of_year|Category_index|EntityType_index|EvidenceRole_index|target|   Category_ohe| EntityType_ohe|EvidenceRole_ohe|        features_raw|            features|       rawPrediction|         probability|prediction|\n",
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+-----------------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+----+-----+---+----+------+------+-----------+------------+--------------+----------------+------------------+------+---------------+---------------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|1245540519230|  657|     11767|  87199|2024-06-04 22:56:27|       524|       563|  LateralMovement|BenignPositive|             User|    Impacted|   98799|138268|   360606|160396|      2610|      3699|         425863|        863|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|2024|    6|  4|  22|    56|    27|          3|          23|          11.0|             1.0|               1.0|   0.0|(19,[11],[1.0])| (32,[1],[1.0])|       (1,[],[])|(90,[0,1,2,3,4,5,...|(90,[0,1,2,3,4,5,...|[0.54238374947441...|[0.45368676128764...|       2.0|\n",
            "|1400159342154|    3|     91158| 632273|2024-06-03 12:58:26|         2|         2|CommandAndControl|BenignPositive|          Machine|    Impacted|    1239|138268|   360606|160396|    441377|    673934|         425863|     453297|      2833|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       0|        0|        242| 1445|10630|2024|    6|  3|  12|    58|    26|          2|          23|           3.0|             3.0|               1.0|   0.0| (19,[3],[1.0])| (32,[3],[1.0])|       (1,[],[])|(90,[0,1,2,3,4,5,...|(90,[0,1,2,3,4,5,...|[0.97982295948012...|[0.68384191530771...|       0.0|\n",
            "|1279900255923|  145|     32247| 131719|2024-06-08 03:20:49|      2932|     10807|  LateralMovement|BenignPositive|          Process|     Related|   98799|  4296|   360606|160396|    441377|    673934|         425863|     453297|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|      14|        22|          3586|       5|       66|        242| 1445|10630|2024|    6|  8|   3|    20|    49|          7|          23|          11.0|             8.0|               0.0|   0.0|(19,[11],[1.0])| (32,[8],[1.0])|   (1,[0],[1.0])|(90,[0,1,2,3,4,5,...|(90,[0,1,2,3,4,5,...|[1.60913838269206...|[0.84728330839378...|       0.0|\n",
            "|  60129547292|  222|     15294| 917686|2024-06-12 12:07:31|         0|         0|    InitialAccess| FalsePositive|CloudLogonSession|     Related|   98799|138268|   360606|160396|    441377|    673934|         425863|     453297|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|2024|    6| 12|  12|     7|    31|          4|          24|           0.0|            11.0|               0.0|   2.0| (19,[0],[1.0])|(32,[11],[1.0])|   (1,[0],[1.0])|(90,[0,1,2,3,6,36...|(90,[0,1,2,3,6,36...|[-2.0804557693544...|[0.01988222197975...|       1.0|\n",
            "| 515396080539|  363|      7615|   5944|2024-06-06 17:42:05|        27|        18|        Discovery|BenignPositive|             User|    Impacted|   98799|138268|   360606|160396|    133549|    673934|         425863|     136104|    153085|          529644|       1631|              635|              860|         2251|           3421|               881|  289573|    117668|          3586|       5|       66|        242| 1445|10630|2024|    6|  6|  17|    42|     5|          5|          23|           8.0|             1.0|               1.0|   0.0| (19,[8],[1.0])| (32,[1],[1.0])|       (1,[],[])|(90,[0,1,2,3,4,5,...|(90,[0,1,2,3,4,5,...|[0.34860044232780...|[0.42329889725604...|       2.0|\n",
            "+-------------+-----+----------+-------+-------------------+----------+----------+-----------------+--------------+-----------------+------------+--------+------+---------+------+----------+----------+---------------+-----------+----------+----------------+-----------+-----------------+-----------------+-------------+---------------+------------------+--------+----------+--------------+--------+---------+-----------+-----+-----+----+-----+---+----+------+------+-----------+------------+--------------+----------------+------------------+------+---------------+---------------+----------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR with Robust Scaler"
      ],
      "metadata": {
        "id": "vx4amPUSY6yS"
      },
      "id": "vx4amPUSY6yS"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_stages = [StringIndexer(inputCol=c, outputCol=c+'_index') for c in ['Category', 'EntityType', 'EvidenceRole']]\n",
        "pipe_stages.append(StringIndexer(inputCol='IncidentGrade', outputCol='target'))\n",
        "\n",
        "pipe_stages.append(OneHotEncoder(inputCols=[c+'_index' for c in ['Category', 'EntityType', 'EvidenceRole']], outputCols=[c+'_ohe' for c in ['Category', 'EntityType', 'EvidenceRole']]))\n",
        "\n",
        "feature_cols = ['Id', 'OrgId', 'IncidentId', 'AlertId', 'DetectorId',\n",
        "                'AlertTitle', 'Category_ohe', 'EntityType_ohe', 'EvidenceRole_ohe',\n",
        "                'DeviceId', 'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn',\n",
        "                'AccountObjectId', 'AccountName', 'DeviceName', 'NetworkMessageId',\n",
        "                'RegistryKey', 'RegistryValueName', 'RegistryValueData', 'ApplicationId',\n",
        "                'ApplicationName', 'OAuthApplicationId', 'FileName', 'FolderPath',\n",
        "                'ResourceIdName', 'OSFamily', 'OSVersion', 'CountryCode', 'State',\n",
        "                'City', 'year', 'month', 'day', 'hour', 'minute', 'second',\n",
        "                'day_of_week', 'week_of_year']\n",
        "\n",
        "\n",
        "\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features_raw')\n",
        "\n",
        "scaler = RobustScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
        "\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='target')\n",
        "\n",
        "pipeline = Pipeline(stages=[timestamp_transformer] + pipe_stages + [assembler, scaler, lr])\n",
        "\n",
        "model = pipeline.fit(df_train)\n",
        "\n",
        "train_prediction = model.transform(df_train)\n",
        "test_prediction = model.transform(df_test)\n",
        "\n",
        "evaluator_macrof1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"fMeasureByLabel\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"recallByLabel\")"
      ],
      "metadata": {
        "id": "Lh-Oo4gWegfu"
      },
      "id": "Lh-Oo4gWegfu",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(train_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(train_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(train_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(train_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "train_crosstab = train_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "train_crosstab.show()"
      ],
      "metadata": {
        "id": "PFKRnKZe5Tzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf2eb08-b095-4897-8083-930415ff647c"
      },
      "id": "PFKRnKZe5Tzu",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Results:\n",
            "Macro F1: 0.5612\n",
            "F1 for class 0: 0.6680\n",
            "F1 for class 1: 0.6177\n",
            "F1 for class 2: 0.2525\n",
            "Precision for class 0: 0.5906\n",
            "Precision for class 1: 0.6017\n",
            "Precision for class 2: 0.5472\n",
            "Recall for class 0: 0.7689\n",
            "Recall for class 1: 0.6346\n",
            "Recall for class 2: 0.1641\n",
            "\n",
            "+-----------------+-------+-------+------+\n",
            "|target_prediction|    0.0|    1.0|   2.0|\n",
            "+-----------------+-------+-------+------+\n",
            "|              1.0|1084913|2108498|129302|\n",
            "|              0.0|3160607| 803503|146707|\n",
            "|              2.0|1106169| 592267|333531|\n",
            "+-----------------+-------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Results:\")\n",
        "macrof1 = evaluator_macrof1.evaluate(test_prediction)\n",
        "print(f\"Macro F1: {macrof1:.4f}\")\n",
        "\n",
        "f1_class_0 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 0})\n",
        "print(f\"F1 for class 0: {f1_class_0:.4f}\")\n",
        "f1_class_1 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 1})\n",
        "print(f\"F1 for class 1: {f1_class_1:.4f}\")\n",
        "f1_class_2 = evaluator_f1.evaluate(test_prediction, {evaluator_f1.metricLabel: 2})\n",
        "print(f\"F1 for class 2: {f1_class_2:.4f}\")\n",
        "\n",
        "precision_class_0 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 0})\n",
        "print(f\"Precision for class 0: {precision_class_0:.4f}\")\n",
        "precision_class_1 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 1})\n",
        "print(f\"Precision for class 1: {precision_class_1:.4f}\")\n",
        "precision_class_2 = evaluator_precision.evaluate(test_prediction, {evaluator_precision.metricLabel: 2})\n",
        "print(f\"Precision for class 2: {precision_class_2:.4f}\")\n",
        "\n",
        "\n",
        "recall_class_0 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 0})\n",
        "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
        "recall_class_1 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 1})\n",
        "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
        "recall_class_2 = evaluator_recall.evaluate(test_prediction, {evaluator_recall.metricLabel: 2})\n",
        "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
        "\n",
        "print()\n",
        "\n",
        "test_crosstab = test_prediction.stat.crosstab(\"target\", \"prediction\")\n",
        "test_crosstab.show()"
      ],
      "metadata": {
        "id": "HC_qGKNSZHnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e64173c-550e-453b-b441-db2a13ba8de7"
      },
      "id": "HC_qGKNSZHnI",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Macro F1: 0.5664\n",
            "F1 for class 0: 0.6680\n",
            "F1 for class 1: 0.6362\n",
            "F1 for class 2: 0.2537\n",
            "Precision for class 0: 0.5925\n",
            "Precision for class 1: 0.6109\n",
            "Precision for class 2: 0.5635\n",
            "Recall for class 0: 0.7655\n",
            "Recall for class 1: 0.6637\n",
            "Recall for class 2: 0.1637\n",
            "\n",
            "+-----------------+-------+------+------+\n",
            "|target_prediction|    0.0|   1.0|   2.0|\n",
            "+-----------------+-------+------+------+\n",
            "|              1.0| 446995|990427| 54932|\n",
            "|              0.0|1341808|351588| 59544|\n",
            "|              2.0| 475791|279134|147773|\n",
            "+-----------------+-------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q4WviprmAdNb"
      },
      "id": "Q4WviprmAdNb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "conda-base-py",
      "name": "workbench-notebooks.m128",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}